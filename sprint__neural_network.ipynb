{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4fgiGyWeICytkbFETDZKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterYves/DIC-ML-Assignmnent/blob/main/sprint__neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependencies\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "a801wnXYyQX6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST Dataset\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LCXikDqSyiwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "JecnbglBycpV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Check the dataset`**"
      ],
      "metadata": {
        "id": "UUGa7KSr2dHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape) # (60000, 28, 28)\n",
        "print(X_test.shape) # (10000, 28, 28)\n",
        "print(X_train[0].dtype) # uint8\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrpm3e_Ey2kM",
        "outputId": "2c1752da-87b7-461c-9036-3d7c706a8b21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Smoothing`**\n",
        "\n"
      ],
      "metadata": {
        "id": "Ys8FEjrj1dha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "metadata": {
        "id": "jUlv51uAy-tS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Visualization of image data`**"
      ],
      "metadata": {
        "id": "hC9jhkl51dY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "# X_train[index]: (784,)\n",
        "# image: (28, 28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Yuun7LxL19tO",
        "outputId": "d8588cee-53f6-4964-ab5f-b18b931a3965"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "image = image.astype(np.float64) ## Convert to float type\n",
        "image -= 105.35 ## Intentionally try to create a negative decimal value\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()\n",
        "print(image) ## Check the value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IBNCTOm-3NY5",
        "outputId": "6eda3026-6804-4f59-8de6-e0862b8fbb3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
            "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
            "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
            "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
            "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
            "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
            "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
            "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
            "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
            "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
            "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
            "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
            "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
            "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
            "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
            "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
            "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
            "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
            "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GkPkN9EM757F",
        "outputId": "1fe514c0-36f7-4093-ed40-597fb6915c6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f763736c310>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Preprocessing`**"
      ],
      "metadata": {
        "id": "UWaXyrtI8FSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float64)\n",
        "X_test = X_test.astype(np.float64)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxL2qBOX_mwI",
        "outputId": "3c7e6c9d-951e-4bda-99a5-f3da23b68d22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ3eYgt6_qJH",
        "outputId": "3d9e95ea-9ef8-45b7-ff51-4867bceb9014"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqLmvABKAHaC",
        "outputId": "ca08ea57-d70f-4433-ee60-590d8e204eb4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network scratch\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Rto_TUl4xjUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem 1-5:** Creating code to determine the initial values of the weights, Implementation of Forward Propagation, Implementation of Cross-Entropy Error, Back-propagation implementation, Estimation\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PeDb0yEkChHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GHYSC2pkoy4L"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "class ScratchSimpleNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    Simple three-layer neural network classifier\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, lr=0.1, epoch=5, batch_size=20, sigma=0.01, activation_func=\"sigmoid\", verbose = True):\n",
        "        self.verbose = verbose\n",
        "        self.params = {}\n",
        "        self.bias = {}\n",
        "        \n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.lr = lr\n",
        "        self.epoch = epoch\n",
        "        self.batch_size = batch_size\n",
        "        self.sigma = sigma\n",
        "        \n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        \n",
        "        if activation_func == \"sigmoid\":\n",
        "            self.forward_activation_func = self._sigmoid_forward\n",
        "            self.backward_activation_func = self._sigmoid_backward\n",
        "        elif activation_func == \"tanh\":\n",
        "            self.forward_activation_func = self._tanh_forward\n",
        "            self.backward_activation_func = self._tanh_backward\n",
        "        else:\n",
        "            raise ValueError(\"No exists such activation function !!\")\n",
        "                \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \n",
        "       ## Whether to record the loss function of verification data\n",
        "        calc_val = (X_val is not None) & (y_val is not None)\n",
        "        \n",
        "        ## One_hot conversion of objective variable\n",
        "        y = self._one_hot_encoding(y) \n",
        "        if calc_val:\n",
        "            y_val = self._one_hot_encoding(y_val) \n",
        "        \n",
        "        ## Initial value parameter set\n",
        "        self._set_parameters(X, y)\n",
        "        \n",
        "        ## Mini batch object definition\n",
        "        get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "        \n",
        "        ## Learning\n",
        "        for ep in range(self.epoch):\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                ## Forward propagation\n",
        "                ## ① Hierarchy＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                A1 = mini_X @ self.params[\"W1\"] + self.bias[\"b1\"]\n",
        "                Z1 = self.forward_activation_func(A1)\n",
        "                ## ② Hierarchy＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                A2 = Z1 @ self.params[\"W2\"] + self.bias[\"b2\"]\n",
        "                Z2 = self.forward_activation_func(A2)\n",
        "                ## ③ Hierarchy＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                A3 = Z2 @ self.params[\"W3\"] + self.bias[\"b3\"]\n",
        "                Z3 = self._softmax(A3)\n",
        "                #＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                \n",
        "               ## Backpropagation\n",
        "                ## ③ Layer＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                deltaA3 = Z3 - mini_y\n",
        "                deltaB3 = np.sum(deltaA3, axis=0)\n",
        "                deltaW3 = Z2.T @ deltaA3\n",
        "\n",
        "                self.params[\"W3\"] -= self.lr * deltaW3\n",
        "                self.bias[\"b3\"] -= self.lr * deltaB3\n",
        "                \n",
        "                deltaZ2 = deltaA3 @ self.params[\"W3\"].T\n",
        "\n",
        "                ## ② Layer＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                deltaA2 = deltaZ2 * self.backward_activation_func(A2) \n",
        "                deltaB2 = np.sum(deltaA2, axis=0)\n",
        "                deltaW2 = Z1.T @ deltaA2\n",
        "\n",
        "                self.params[\"W2\"] -= self.lr * deltaW2\n",
        "                self.bias[\"b2\"] -= self.lr * deltaB2\n",
        "                \n",
        "                deltaZ1 = deltaA2 @ self.params[\"W2\"].T\n",
        "                ## ① Layer＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "                deltaA1 = deltaZ1 * self.backward_activation_func(A1) \n",
        "                deltaB1 = np.sum(deltaA1, axis=0)\n",
        "                deltaW1 = mini_X.T @ deltaA1\n",
        "\n",
        "                self.params[\"W1\"] -= self.lr * deltaW1\n",
        "                self.bias[\"b1\"] -= self.lr * deltaB1\n",
        "                #＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "\n",
        "            ## Record of loss\n",
        "            tr_loss = self._cross_entropy(self.predict_prob(X), y)\n",
        "            self.train_loss.append(tr_loss)\n",
        "            \n",
        "            if self.verbose:\n",
        "                    print(\"Train loss of epoch {}: {}\".format(ep, tr_loss))\n",
        "            \n",
        "            if calc_val:\n",
        "                va_loss = self._cross_entropy(self.predict_prob(X_val), y_val)\n",
        "                self.val_loss.append(va_loss)\n",
        "                \n",
        "                \n",
        "    def predict_prob(self, X):\n",
        "        ## Forward propagation\n",
        "        ## ① Hierarchy＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "        A1 = X @ self.params[\"W1\"] + self.bias[\"b1\"]\n",
        "        Z1 = self.forward_activation_func(A1)\n",
        "        ## ② Hierarchy＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "        A2 = Z1 @ self.params[\"W2\"] + self.bias[\"b2\"]\n",
        "        Z2 = self.forward_activation_func(A2)\n",
        "        ## ③ Hierarchy＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "        A3 = Z2 @ self.params[\"W3\"] + self.bias[\"b3\"]\n",
        "        y = self._softmax(A3)\n",
        "        ##＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
        "        \n",
        "        return y\n",
        "                \n",
        "    def predict(self, X):\n",
        "        y = np.argmax(self.predict_prob(X), axis=1)\n",
        "         \n",
        "        return y\n",
        "    \n",
        "    def _set_parameters(self, X, y):\n",
        "        ## Set the number of features and the number of classes\n",
        "        self.n_features = X.shape[1] \n",
        "        self.n_output = y.shape[1]\n",
        "        \n",
        "        ## Initial weight\n",
        "        self.params[\"W1\"] = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
        "        self.params[\"W2\"] = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
        "        self.params[\"W3\"] = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
        "        \n",
        "       ## Bias initial value\n",
        "        self.bias[\"b1\"] = self.sigma * np.random.randn(self.n_nodes1, )\n",
        "        self.bias[\"b2\"] = self.sigma * np.random.randn(self.n_nodes2, )\n",
        "        self.bias[\"b3\"] = self.sigma * np.random.randn(self.n_output, )\n",
        "    \n",
        "    def _sigmoid_forward(self, X):\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "    \n",
        "    def _tanh_forward(self, X):\n",
        "        return np.tanh(X)\n",
        "    \n",
        "    def _sigmoid_backward(self, X):\n",
        "        return (1-self._sigmoid_forward(X)) * self._sigmoid_forward(X)\n",
        "    \n",
        "    def _tanh_backward(self, X):\n",
        "        return (1 - self._tanh_forward(X)**2)\n",
        "    \n",
        "    def _softmax(self, X):\n",
        "        X = X - np.max(X)\n",
        "        return np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
        "        \n",
        "    def _one_hot_encoding(self, y):\n",
        "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "        y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
        "        return y_one_hot\n",
        "\n",
        "    def _cross_entropy(self, X, y):\n",
        "        batch_size = len(X)\n",
        "        delta = 1e-7\n",
        "        return -np.sum(y * np.log(X+delta)) / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to get a mini-batch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X :The following form ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int64)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "      if self._counter >= self._stop:\n",
        "          raise StopIteration()\n",
        "      p0 = self._counter*self.batch_size\n",
        "      p1 = self._counter*self.batch_size + self.batch_size\n",
        "      self._counter += 1\n",
        "      return self._X[p0:p1], self._y[p0:p1]"
      ],
      "metadata": {
        "id": "-WKAZ-m8BZ-8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem 6 Learning and Estimation**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NfCWudl0DbYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn = ScratchSimpleNeuralNetrowkClassifier(400,200, epoch=50,lr=1e-3)\n",
        "nn.fit(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMht4BLmDeah",
        "outputId": "23d3f7a1-9b9c-4ca6-dda8-9bc1ed6f14d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss of epoch 0: 2.3073592872982536\n",
            "Train loss of epoch 1: 2.307463188526911\n",
            "Train loss of epoch 2: 2.305411952837007\n",
            "Train loss of epoch 3: 2.263152212300946\n",
            "Train loss of epoch 4: 1.5008779009733195\n",
            "Train loss of epoch 5: 1.174653288017997\n",
            "Train loss of epoch 6: 0.8174204805929709\n",
            "Train loss of epoch 7: 0.70967508544467\n",
            "Train loss of epoch 8: 0.6332521514177104\n",
            "Train loss of epoch 9: 0.5648940751081594\n",
            "Train loss of epoch 10: 0.5159526968798998\n",
            "Train loss of epoch 11: 0.4797128261369226\n",
            "Train loss of epoch 12: 0.44668945007420735\n",
            "Train loss of epoch 13: 0.4132725332661111\n",
            "Train loss of epoch 14: 0.3847478182787259\n",
            "Train loss of epoch 15: 0.36395694644930265\n",
            "Train loss of epoch 16: 0.3479439227832155\n",
            "Train loss of epoch 17: 0.33439420772729556\n",
            "Train loss of epoch 18: 0.32227227779275025\n",
            "Train loss of epoch 19: 0.31113749926871126\n",
            "Train loss of epoch 20: 0.30076213270250685\n",
            "Train loss of epoch 21: 0.29097626860391335\n",
            "Train loss of epoch 22: 0.28163099153122256\n",
            "Train loss of epoch 23: 0.2726051383125078\n",
            "Train loss of epoch 24: 0.26381660336233187\n",
            "Train loss of epoch 25: 0.25522511189508507\n",
            "Train loss of epoch 26: 0.24682673323620205\n",
            "Train loss of epoch 27: 0.23864380109751254\n",
            "Train loss of epoch 28: 0.230713109449557\n",
            "Train loss of epoch 29: 0.223074475400432\n",
            "Train loss of epoch 30: 0.2157614637661388\n",
            "Train loss of epoch 31: 0.20879555603316882\n",
            "Train loss of epoch 32: 0.20218417264964011\n",
            "Train loss of epoch 33: 0.19592197886146828\n",
            "Train loss of epoch 34: 0.1899941731022175\n",
            "Train loss of epoch 35: 0.18438028744234036\n",
            "Train loss of epoch 36: 0.1790574235249647\n",
            "Train loss of epoch 37: 0.17400247717440864\n",
            "Train loss of epoch 38: 0.16919341280761524\n",
            "Train loss of epoch 39: 0.16460987603523608\n",
            "Train loss of epoch 40: 0.16023342872949775\n",
            "Train loss of epoch 41: 0.15604758979866143\n",
            "Train loss of epoch 42: 0.15203776979626463\n",
            "Train loss of epoch 43: 0.14819113473567047\n",
            "Train loss of epoch 44: 0.14449641831156806\n",
            "Train loss of epoch 45: 0.14094370423999397\n",
            "Train loss of epoch 46: 0.1375242056176798\n",
            "Train loss of epoch 47: 0.13423006657909606\n",
            "Train loss of epoch 48: 0.13105420202477633\n",
            "Train loss of epoch 49: 0.12799017882362398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nn.predict(X_test)\n",
        "print(\"pred:\", y_pred)\n",
        "print(\"ans:\", y_test)\n",
        "print(\"accuracy score:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1WI7AdgFUoh",
        "outputId": "ca1cee0c-6cfb-495f-bfb1-ceb025e37fed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: [7 2 1 ... 4 5 6]\n",
            "ans: [7 2 1 ... 4 5 6]\n",
            "accuracy score: 0.9598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[Problem 7] Plotting the learning curve**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "maA3A9VNqKka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(nn.train_loss, marker=\"o\", label=\"train_loss\", c= \"red\")\n",
        "plt.plot(nn.val_loss, marker=\"^\", label=\"val_loss\")\n",
        "plt.title(\"Loss transition by learning\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "tkMsFN41mlNW",
        "outputId": "f09bb61f-3744-4cd8-d243-60888ba06901"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.train_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuG1-Px9u4fr",
        "outputId": "d5c55965-0a89-4bfd-c2f8-e31faf10531b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3073592872982536,\n",
              " 2.307463188526911,\n",
              " 2.305411952837007,\n",
              " 2.263152212300946,\n",
              " 1.5008779009733195,\n",
              " 1.174653288017997,\n",
              " 0.8174204805929709,\n",
              " 0.70967508544467,\n",
              " 0.6332521514177104,\n",
              " 0.5648940751081594,\n",
              " 0.5159526968798998,\n",
              " 0.4797128261369226,\n",
              " 0.44668945007420735,\n",
              " 0.4132725332661111,\n",
              " 0.3847478182787259,\n",
              " 0.36395694644930265,\n",
              " 0.3479439227832155,\n",
              " 0.33439420772729556,\n",
              " 0.32227227779275025,\n",
              " 0.31113749926871126,\n",
              " 0.30076213270250685,\n",
              " 0.29097626860391335,\n",
              " 0.28163099153122256,\n",
              " 0.2726051383125078,\n",
              " 0.26381660336233187,\n",
              " 0.25522511189508507,\n",
              " 0.24682673323620205,\n",
              " 0.23864380109751254,\n",
              " 0.230713109449557,\n",
              " 0.223074475400432,\n",
              " 0.2157614637661388,\n",
              " 0.20879555603316882,\n",
              " 0.20218417264964011,\n",
              " 0.19592197886146828,\n",
              " 0.1899941731022175,\n",
              " 0.18438028744234036,\n",
              " 0.1790574235249647,\n",
              " 0.17400247717440864,\n",
              " 0.16919341280761524,\n",
              " 0.16460987603523608,\n",
              " 0.16023342872949775,\n",
              " 0.15604758979866143,\n",
              " 0.15203776979626463,\n",
              " 0.14819113473567047,\n",
              " 0.14449641831156806,\n",
              " 0.14094370423999397,\n",
              " 0.1375242056176798,\n",
              " 0.13423006657909606,\n",
              " 0.13105420202477633,\n",
              " 0.12799017882362398]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruZhYTxGvHdz",
        "outputId": "c521ce66-27d0-478b-f938-5529f459e5d8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3065495400889,\n",
              " 2.3064144127446236,\n",
              " 2.3041228368178635,\n",
              " 2.2608997478022546,\n",
              " 1.4827287733984984,\n",
              " 1.163217727993498,\n",
              " 0.8098861854227077,\n",
              " 0.7027393975707981,\n",
              " 0.6257810340505046,\n",
              " 0.5568498344819298,\n",
              " 0.5082160286214853,\n",
              " 0.47311870391194444,\n",
              " 0.4416562574634105,\n",
              " 0.41003067903633894,\n",
              " 0.3832099250160024,\n",
              " 0.3637820110753074,\n",
              " 0.34881016782177066,\n",
              " 0.3360024084287885,\n",
              " 0.32435568589835745,\n",
              " 0.31348390026750905,\n",
              " 0.3032276174680231,\n",
              " 0.2934846398218144,\n",
              " 0.2841588203262821,\n",
              " 0.27516146714486567,\n",
              " 0.2664258668650526,\n",
              " 0.25791649221859037,\n",
              " 0.24962950047815502,\n",
              " 0.24158659452911943,\n",
              " 0.2338249505411346,\n",
              " 0.2263860251679525,\n",
              " 0.21930594231954323,\n",
              " 0.21260924684730967,\n",
              " 0.20630646894863788,\n",
              " 0.2003948544893326,\n",
              " 0.19486105576933094,\n",
              " 0.18968452720046347,\n",
              " 0.18484068904169115,\n",
              " 0.1803033844211272,\n",
              " 0.1760465509328238,\n",
              " 0.1720452493284819,\n",
              " 0.16827624614449663,\n",
              " 0.1647183096562809,\n",
              " 0.16135232116652634,\n",
              " 0.15816126093658997,\n",
              " 0.1551301055007988,\n",
              " 0.1522456652241412,\n",
              " 0.14949639000660125,\n",
              " 0.14687216853317422,\n",
              " 0.1443641374107984,\n",
              " 0.14196450456187942]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}